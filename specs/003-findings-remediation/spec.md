# Feature Specification: Findings & Remediation Management

**Feature Branch**: `003-findings-remediation`
**Created**: 2026-01-17
**Status**: Draft
**Input**: User description: "Epic 3: Findings & Remediation"

## Clarifications

### Session 2026-01-17

- Q: Should findings filtering work across multiple scans or single-scan only? → A: Cross-scan view - Users can view/filter all findings across their organization's scans.
- Q: What is the maximum character limit for finding notes? → A: Standard notes - 10,000 characters max.
- Q: What is the audit log retention period? → A: 2 years retention.
- Q: Who can change finding status within an organization? → A: All org members - Any organization member can update any finding's status.
- Q: Where do users access the cross-scan findings view? → A: Dashboard widget - Summary widget on main dashboard with link to full view.
- Q: What happens to audit log entries after the 2-year retention period expires? → A: Auto-purge - Scheduled job deletes logs older than 2 years.
- Q: When a Finding is deleted, should FindingNotes be retained for 2 years like audit logs? → A: Delete notes - Cascade-delete notes with finding; only AuditLog entries are retained for compliance.
- Q: What is the expected maximum number of findings per organization where performance targets must be met? → A: 10,000 findings - Moderate scale, typical enterprise usage.
- Q: How should performance targets (SC-003/SC-004/SC-006) be validated? → A: Manual - Developer spot-check with browser DevTools during testing.

## Overview

This epic adds findings management and remediation tracking capabilities to Shannon's web dashboard. Security findings are already generated by Shannon's pentesting workflow and stored in the database with fields for status, severity, CWE, CVSS, and remediation guidance. This epic enables users to view detailed findings, track remediation progress, collaborate on fixes, and manage the full lifecycle from discovery to resolution.

## User Scenarios & Testing *(mandatory)*

### User Story 1 - Finding Detail View & Status Management (Priority: P1)

As a security analyst, I want to view detailed information about each finding and update its status so that I can track remediation progress and document resolution decisions.

**Why this priority**: This is the foundational capability that unlocks all other remediation workflows. Without the ability to view findings in detail and update their status, no remediation tracking can occur. The status field already exists in the database but has no UI.

**Independent Test**: Can be fully tested by navigating to a finding, viewing all its details (title, description, severity, evidence, remediation guidance), and updating its status from "open" to "fixed" or "accepted_risk". Delivers immediate value by enabling basic remediation tracking.

**Acceptance Scenarios**:

1. **Given** a completed scan with findings, **When** a user clicks on a finding from the scan detail page, **Then** they see a dedicated finding detail view with title, severity, description, category, CWE reference, CVSS score, evidence, and remediation guidance.

2. **Given** a finding detail view, **When** the user changes the status from "open" to "fixed", **Then** the status is persisted, a timestamp is recorded, and the UI reflects the new status immediately.

3. **Given** a finding with status "open", **When** the user selects "Accepted Risk" and provides a justification reason, **Then** the status changes to "accepted_risk" with the justification stored and visible.

4. **Given** a finding detail view, **When** the user marks a finding as "False Positive" with an explanation, **Then** the status changes to "false_positive" and the finding is excluded from active vulnerability counts.

5. **Given** any finding status change, **When** the change is saved, **Then** an audit log entry is created recording who made the change, when, and the previous/new status values.

---

### User Story 2 - Remediation Notes & Activity History (Priority: P2)

As a security analyst or developer, I want to add notes and comments to findings so that I can document remediation attempts, share context with team members, and maintain a history of actions taken.

**Why this priority**: Collaboration is essential for effective remediation. Notes enable team communication, document troubleshooting steps, and provide audit trails. This builds on P1's status management to create a complete remediation record.

**Independent Test**: Can be tested by adding a note to a finding, viewing the activity history, and verifying notes persist and display chronologically. Delivers value by enabling team collaboration without requiring full assignment workflows.

**Acceptance Scenarios**:

1. **Given** a finding detail view, **When** the user adds a text note, **Then** the note is saved with the author's identity and timestamp, and appears in the finding's activity history.

2. **Given** a finding with multiple notes and status changes, **When** viewing the activity history, **Then** all activities are displayed in reverse chronological order showing the type (note, status change), author, timestamp, and content.

3. **Given** a note being created, **When** the user submits the note, **Then** the note content supports basic formatting (line breaks, code blocks) for documenting technical details.

4. **Given** a finding's activity history, **When** a status change entry is displayed, **Then** it shows the previous status, new status, who made the change, and any associated justification text.

---

### User Story 3 - Findings List with Filtering & Search (Priority: P3)

As a security analyst, I want to filter and search across all findings from my organization's scans so that I can quickly find specific vulnerabilities, prioritize remediation by severity, and track overall remediation progress across my security portfolio.

**Why this priority**: As the number of findings grows, efficient navigation becomes critical. Filtering by status enables tracking "what's left to fix" while severity filters help prioritize work. This enhances usability of the existing findings list.

**Independent Test**: Can be tested by applying filters (severity, status, category) to a findings list and verifying results match filter criteria. Search can be tested by entering keywords and verifying matching findings are returned.

**Acceptance Scenarios**:

1. **Given** a scan with multiple findings, **When** the user applies a severity filter (e.g., "Critical" and "High"), **Then** only findings matching those severities are displayed.

2. **Given** a findings list, **When** the user filters by status "open", **Then** only unresolved findings are shown, hiding fixed, accepted_risk, and false_positive findings.

3. **Given** a findings list, **When** the user enters a search term, **Then** findings matching the term in title, description, or CWE are displayed.

4. **Given** multiple filters applied, **When** viewing results, **Then** a clear indication shows which filters are active with the ability to remove individual filters or clear all.

5. **Given** a filtered findings list, **When** the user views summary statistics, **Then** the counts reflect the filtered subset (e.g., "Showing 5 of 23 findings").

---

### User Story 4 - Bulk Status Updates (Priority: P4)

As a security analyst managing many findings, I want to update the status of multiple findings at once so that I can efficiently process large sets of similar vulnerabilities after remediation.

**Why this priority**: Efficiency improvement for power users dealing with many findings. Lower priority because P1-P3 provide core functionality; bulk operations are an optimization.

**Independent Test**: Can be tested by selecting multiple findings, applying a bulk status change, and verifying all selected findings are updated with appropriate audit logs.

**Acceptance Scenarios**:

1. **Given** a findings list view, **When** the user enters selection mode and checks multiple findings, **Then** a bulk actions toolbar appears showing the count of selected items.

2. **Given** multiple findings selected, **When** the user chooses "Mark as Fixed" from bulk actions, **Then** all selected findings are updated to "fixed" status with a single confirmation.

3. **Given** a bulk status update, **When** the action completes, **Then** individual audit log entries are created for each finding documenting the bulk operation.

4. **Given** selected findings of mixed categories, **When** attempting bulk status change, **Then** the system allows the operation (status is independent of category).

---

### Edge Cases

- What happens when a user tries to change status without providing required justification for "Accepted Risk"?
  - System prevents the status change and displays a validation message requiring justification text.

- How does the system handle concurrent status updates to the same finding by different users?
  - Last write wins with the activity history showing both changes. Users see the current status upon page refresh.

- What happens when filtering returns zero results?
  - Display a clear "No findings match your filters" message with a button to clear all filters.

- How are findings handled when a scan is deleted?
  - Findings and their notes are cascade-deleted with the scan. Audit log entries (status changes, note creation events) are retained for 2 years for compliance, then auto-purged by a scheduled job.

- What happens when viewing a finding from a scan that is still running?
  - Finding is viewable but a notice indicates the scan is in progress and more findings may appear.

## Requirements *(mandatory)*

### Functional Requirements

- **FR-001**: System MUST display a dedicated finding detail view showing title, severity, description, category, CWE reference, CVSS score, evidence data, and remediation guidance.

- **FR-002**: System MUST allow users to update finding status to one of: "open", "fixed", "accepted_risk", "false_positive".

- **FR-003**: System MUST require justification text when changing status to "accepted_risk" or "false_positive".

- **FR-004**: System MUST record an audit log entry for every finding status change including: user identity, timestamp, previous status, new status, and justification (if applicable).

- **FR-005**: System MUST allow users to add text notes to findings with support for basic formatting (line breaks, code blocks).

- **FR-006**: System MUST display an activity history on each finding showing all notes and status changes in reverse chronological order.

- **FR-007**: System MUST provide filtering capabilities on findings lists by: severity (multi-select), status (multi-select), and category (multi-select).

- **FR-008**: System MUST provide text search across finding title, description, and CWE identifier.

- **FR-009**: System MUST display active filter indicators with the ability to remove individual filters or clear all.

- **FR-010**: System MUST update summary statistics to reflect filtered results.

- **FR-011**: System MUST support bulk selection of findings with a visible count of selected items.

- **FR-012**: System MUST allow bulk status updates for selected findings with a single confirmation action.

- **FR-013**: System MUST create individual audit log entries for each finding in a bulk operation.

- **FR-014**: System MUST respect organization-level access controls, ensuring users can only view/modify findings within their organization's scans. All organization members have equal permissions to update finding status and add notes.

- **FR-015**: System MUST display evidence data (when available) in a readable format showing exploitation steps, payloads, and proof of impact.

- **FR-016**: System MUST provide a cross-scan findings view allowing users to view, filter, and search all findings across their organization's scans.

- **FR-017**: System MUST retain audit log entries for finding status changes and notes for a minimum of 2 years, even after the associated scan or finding is deleted. A scheduled cleanup job MUST purge audit logs older than 2 years.

- **FR-018**: System MUST display a findings summary widget on the main dashboard showing key metrics (open findings by severity) with a link to the full cross-scan findings view.

### Key Entities

- **Finding**: A discovered security vulnerability with severity, status, category, evidence, and remediation guidance. Extended with activity history (notes and status changes).

- **FindingNote**: A user-added comment on a finding with author, timestamp, and content (max 10,000 characters). Supports basic text formatting. Cascade-deleted when parent finding is deleted (not retained like audit logs).

- **FindingStatusChange**: An audit record of a status transition including previous/new status, user, timestamp, and optional justification.

- **ActivityEntry**: A unified view combining notes and status changes for chronological display in the activity history.

## Success Criteria *(mandatory)*

### Measurable Outcomes

- **SC-001**: Users can view complete finding details and update status within 3 clicks from the scan results page.

- **SC-002**: 100% of finding status changes are captured in the audit log with user attribution and timestamp.

- **SC-003**: Users can filter findings lists and see results update within 1 second of applying filters.

- **SC-004**: Bulk status updates process at least 50 findings in a single operation within 5 seconds.

- **SC-005**: Activity history displays all notes and status changes for a finding in correct chronological order.

- **SC-006**: Search returns relevant findings matching keywords in title, description, or CWE within 2 seconds.

- **SC-007**: Users report that the remediation tracking workflow meets their needs (validated through user testing).

- **SC-008**: Zero unauthorized access to findings outside user's organization (security requirement).

## Assumptions

- Users have already completed scans that generated findings (Epic 2 functionality).
- The existing Finding model's status field values (open, fixed, accepted_risk, false_positive) are sufficient for remediation tracking.
- Organization-scoped access control patterns from Epic 2 apply to findings management.
- The existing AuditLog model can be extended or a new audit mechanism created for finding-specific events.
- Basic text formatting (line breaks, code blocks) is sufficient for notes; rich text editing is not required.
- Real-time collaboration features (live updates, presence indicators) are out of scope for this epic.
- Integration with external issue trackers (Jira, GitHub Issues) is out of scope for this epic.
- Performance targets (SC-003, SC-004, SC-006) are validated against organizations with up to 10,000 findings. Validation is manual (browser DevTools spot-check), not automated CI/CD tests.

## Out of Scope

- Assignment of findings to specific team members (future epic)
- SLA/deadline tracking for remediation (future epic)
- Automated remediation suggestions beyond stored guidance (future epic)
- Integration with external ticketing systems (future epic)
- Real-time collaborative editing of notes (future epic)
- Remediation verification/re-scanning (future epic)
- Custom status values beyond the four defined options (future epic)
