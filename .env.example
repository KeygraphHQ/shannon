# Shannon Environment Configuration
# Copy this file to .env and fill in your credentials

# Recommended output token configuration for larger tool outputs
CLAUDE_CODE_MAX_OUTPUT_TOKENS=64000

# =============================================================================
# OPTION 1: Direct Anthropic (default, no router)
# =============================================================================
ANTHROPIC_API_KEY=your-api-key-here

# OR use OAuth token instead
# CLAUDE_CODE_OAUTH_TOKEN=your-oauth-token-here

# =============================================================================
# OPTION 2: Router Mode (use alternative providers)
# =============================================================================
# Enable router mode by running: ./shannon start ... ROUTER=true
# Then configure ONE of the providers below:

# --- OpenAI ---
# OPENAI_API_KEY=sk-your-openai-key
# ROUTER_DEFAULT=openai,gpt-5.2

# --- OpenRouter (access Gemini 3 models via single API) ---
# OPENROUTER_API_KEY=sk-or-your-openrouter-key
# ROUTER_DEFAULT=openrouter,google/gemini-3-flash-preview

# --- Ollama (local models via OpenAI-compatible API) ---
# First, run: ollama serve
# Then set the base URL to your Ollama instance:
# OLLAMA_BASE_URL=http://localhost:11434/v1
# ROUTER_DEFAULT=ollama,llama3.3:70b
#
# For Docker, use host.docker.internal:
# OLLAMA_BASE_URL=http://host.docker.internal:11434/v1

# =============================================================================
# Available Models
# =============================================================================
# OpenAI:     gpt-5.2, gpt-5-mini
# OpenRouter: google/gemini-3-flash-preview
# Ollama:     llama3.3:70b, qwen2.5:72b, deepseek-r1:70b (or any model you have pulled)
