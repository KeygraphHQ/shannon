# Shannon Environment Configuration
# Copy this file to .env and fill in your credentials

# =============================================================================
# OPTION 1: Direct Anthropic (default, no router)
# =============================================================================
ANTHROPIC_API_KEY=your-api-key-here

# OR use OAuth token instead
# CLAUDE_CODE_OAUTH_TOKEN=your-oauth-token-here

# =============================================================================
# OPTION 2: Router Mode (use alternative providers)
# =============================================================================
# Enable router mode by running: ./shannon start ... ROUTER=true
# Then configure ONE of the providers below:

# --- OpenAI ---
# OPENAI_API_KEY=sk-your-openai-key
# ROUTER_DEFAULT=openai,gpt-5.2

# --- OpenRouter (access Gemini 3 models via single API) ---
# OPENROUTER_API_KEY=sk-or-your-openrouter-key
# ROUTER_DEFAULT=openrouter,google/gemini-3-flash-preview

# =============================================================================
# OPTION 3: OpenAI-Compatible (local models, minimax, ollama, vLLM, etc.)
# =============================================================================
# Native support - no router. Use with: ./shannon start ... PROVIDER=openai
# Or set AI_PROVIDER=openai in .env

# AI_PROVIDER=openai
# AI_BASE_URL=http://localhost:8080/v1
# AI_MODEL=minimax
# AI_API_KEY=your-key-or-empty-for-local
# AI_REQUEST_TIMEOUT_MS=120000  # 2 min default; increase for slow local models
# AI_MAX_CONCURRENT_REQUESTS=2  # Max simultaneous completions API calls (for rate-limiting local models)

# =============================================================================
# Available Models
# =============================================================================
# OpenAI:     gpt-5.2, gpt-5-mini
# OpenRouter: google/gemini-3-flash-preview
# Local:      minimax, ollama models, vLLM, etc. (via OPTION 3)
